{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow_hub in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.14.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.45.1)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.8)\n",
      "Requirement already satisfied: ragas in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2.14)\n",
      "Requirement already satisfied: openai in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.65.4)\n",
      "Collecting load_dotenv\n",
      "  Downloading load_dotenv-0.1.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (0.24.7)\n",
      "Requirement already satisfied: Pillow in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow_hub) (2.18.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.16.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.42 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_openai) (0.3.43)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (3.2.0)\n",
      "Requirement already satisfied: langchain in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (0.3.2)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (0.3.1)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (1.6.0)\n",
      "Requirement already satisfied: appdirs in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (1.4.4)\n",
      "Requirement already satisfied: pydantic>=2 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (2.10.6)\n",
      "Requirement already satisfied: diskcache>=5.6.3 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ragas) (5.6.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from load_dotenv) (1.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
      "Requirement already satisfied: certifi in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2024.9.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (0.1.132)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.42->langchain_openai) (1.33)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2->ragas) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2->ragas) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets->ragas) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets->ragas) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets->ragas) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets->ragas) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets->ragas) (3.10.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain->ragas) (2.0.34)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain->ragas) (0.3.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community->ragas) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community->ragas) (2.5.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets->ragas) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets->ragas) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets->ragas) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets->ragas) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets->ragas) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets->ragas) (1.11.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.42->langchain_openai) (2.3)\n",
      "Requirement already satisfied: rich in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.1)\n",
      "Requirement already satisfied: namex in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain_openai) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.42->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->ragas) (3.1.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (1.0.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\akindu himan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Downloading load_dotenv-0.1.0-py3-none-any.whl (7.2 kB)\n",
      "Installing collected packages: load_dotenv\n",
      "Successfully installed load_dotenv-0.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy sentence-transformers tensorflow tensorflow_hub scipy transformers langchain_openai ragas openai load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from numpy.linalg import norm\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from transformers import BertTokenizer\n",
    "import scipy.special\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ragas libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import ContextEntityRecall\n",
    "from ragas.metrics import Faithfulness\n",
    "from ragas import SingleTurnSample\n",
    "from langchain_openai import ChatOpenAI\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics import LLMContextPrecisionWithReference\n",
    "from ragas.metrics import ContextEntityRecall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "# Initialize the OpenAI LLM and wrap it\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "wrapped_llm = LangchainLLMWrapper(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_context_precision(Question, ground_truth_Context, Context):\n",
    "    context_precision = LLMContextPrecisionWithReference(llm=wrapped_llm)\n",
    "    sample = SingleTurnSample(\n",
    "        user_input=Question,\n",
    "        reference=ground_truth_Context,\n",
    "        retrieved_contexts=Context,\n",
    "    )\n",
    "    score = context_precision.single_turn_ascore(sample)\n",
    "    print(f\"LLM-based context precision with reference: {score}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_context_entity_recall(ground_truth_Context, Context):\n",
    "    # Create a sample for evaluation\n",
    "    sample = SingleTurnSample(\n",
    "        reference=ground_truth_Context,\n",
    "        retrieved_contexts=Context,\n",
    "    )\n",
    "\n",
    "    # Initialize the ContextEntityRecall scorer with the wrapped LLM\n",
    "    scorer = ContextEntityRecall(llm=wrapped_llm)\n",
    "\n",
    "    # Calculate the score\n",
    "    score = scorer.single_turn_ascore(sample)\n",
    "    print(f\"LLM-based context entities recall with reference answer: {score}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_faithfulness(Question, Answer, Context):\n",
    "    sample = SingleTurnSample(\n",
    "        user_input=Question,\n",
    "        response=Answer,\n",
    "        retrieved_contexts=Context\n",
    "    )\n",
    "\n",
    "    scorer = Faithfulness(llm=wrapped_llm)\n",
    "    score = scorer.single_turn_ascore(sample)\n",
    "    print(f\"Faithfulness: {score}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticipantVisibleError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    return np.dot(a, b) / (norm(a) * norm(b) + 1e-8)  # Avoid division by zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    \n",
    "    # Drop the row ID column\n",
    "    solution = solution.drop(columns=[row_id_column_name])\n",
    "    submission = submission.drop(columns=[row_id_column_name])\n",
    "\n",
    "    # Validate columns\n",
    "    required_submission_cols = {'Question', 'Context', 'Answer', 'Sections', 'Pages'}\n",
    "    required_solution_cols = {'Question', 'ground_truth_Context', 'ground_truth_Answer', 'ground_truth_Sections', 'ground_truth_Pages'}\n",
    "\n",
    "    if not required_submission_cols.issubset(submission.columns):\n",
    "        missing = required_submission_cols - set(submission.columns)\n",
    "        raise ParticipantVisibleError(f\"Missing columns in submission: {missing}\")\n",
    "\n",
    "    if not required_solution_cols.issubset(solution.columns):\n",
    "        missing = required_solution_cols - set(solution.columns)\n",
    "        raise ParticipantVisibleError(f\"Missing columns in solution: {missing}\")\n",
    "\n",
    "    # Merge on 'question'\n",
    "    merged = pd.merge(solution, submission, on='Question', how='inner')\n",
    "\n",
    "    if merged.empty:\n",
    "        raise ParticipantVisibleError(\"No matching questions between submission and solution.\")\n",
    "\n",
    "    # Initialize models\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    bem = hub.load('https://www.kaggle.com/models/google/bert/TensorFlow2/answer-equivalence-bem/1')\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    # Initialize scores\n",
    "    context_matching_scores = []\n",
    "    context_precision_scores = []\n",
    "    context_entity_recall_scores = []\n",
    "    faithfulness_scores = []\n",
    "    answer_correctness_scores = []\n",
    "\n",
    "    for _, row in merged.iterrows():\n",
    "        try:\n",
    "            q_emb = model.encode(row[\"Question\"])\n",
    "            ctx_emb = model.encode(row[\"Context\"])\n",
    "            context_matching_scores.append(cosine_sim(q_emb, ctx_emb))\n",
    "            print(\"done 1\")\n",
    "\n",
    "            Question = row[\"Question\"]\n",
    "            Context = row[\"Context\"]\n",
    "            ground_truth_Context = row[\"ground_truth_Context\"]\n",
    "            ground_truth_Answer = row[\"ground_truth_Answer\"]\n",
    "            Answer = row[\"Answer\"]\n",
    "\n",
    "            context_precision_scores.append(calculate_context_precision(Question, ground_truth_Context, Context))\n",
    "            context_entity_recall_scores.append(evaluate_context_entity_recall(ground_truth_Context, Context))\n",
    "            faithfulness_scores.append(evaluate_faithfulness(Question, Answer, Context))\n",
    "            print(\"done 4\")\n",
    "\n",
    "            input_text = f\"[CLS] {Question} [SEP] {ground_truth_Answer} [SEP] {Answer} [SEP]\"\n",
    "            # Tokenize input\n",
    "            encoded = tokenizer(\n",
    "                input_text,\n",
    "                return_tensors=\"tf\",\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "            )\n",
    "            # Prepare input dict with correct types\n",
    "            inputs = {\n",
    "                \"input_ids\": tf.cast(encoded[\"input_ids\"], tf.int64),\n",
    "                \"segment_ids\": tf.cast(encoded[\"token_type_ids\"], tf.int64)\n",
    "            }\n",
    "            # Run model\n",
    "            raw_outputs = bem(inputs)\n",
    "            # Convert logits to probabilities using softmax\n",
    "            probabilities = scipy.special.softmax(raw_outputs.numpy(), axis=1)\n",
    "            # BERT Answer Equivalence Score (Probability of class 1)\n",
    "            equivalence_score = probabilities[0][1]\n",
    "            answer_correctness_scores.append(equivalence_score)\n",
    "            print(\"done 5\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ParticipantVisibleError(f\"Embedding computation failed for a row: {e}\")\n",
    "\n",
    "    # Convert to numpy arrays and clip values\n",
    "    context_matching_scores = np.clip(np.array(context_matching_scores), 0, 1)\n",
    "    context_precision_scores = np.clip(np.array(context_precision_scores), 0, 1)\n",
    "    context_entity_recall_scores = np.clip(np.array(context_entity_recall_scores), 0, 1)\n",
    "    faithfulness_scores = np.clip(np.array(faithfulness_scores), 0, 1)\n",
    "    answer_correctness_scores = np.clip(np.array(answer_correctness_scores), 0, 1)\n",
    "    \n",
    "    # Add scores to submission DataFrame\n",
    "    submission['Context Matching Score'] = context_matching_scores\n",
    "    submission['Context Precision Score'] = context_precision_scores\n",
    "    submission['Context Entity Recall Score'] = context_entity_recall_scores\n",
    "    submission['Faithfulness Score'] = faithfulness_scores\n",
    "    submission['Answer Correctness Score'] = answer_correctness_scores\n",
    "\n",
    "    # Compute weighted average\n",
    "    final_scores = (\n",
    "        0.1 * context_matching_scores +\n",
    "        0.2 * context_precision_scores +\n",
    "        0.2 * context_entity_recall_scores +\n",
    "        0.2 * faithfulness_scores +\n",
    "        0.3 * answer_correctness_scores\n",
    "    )\n",
    "\n",
    "    # Add final score to submission DataFrame\n",
    "    submission['Final Score'] = final_scores\n",
    "\n",
    "    # Add total score to submission DataFrame\n",
    "    Total_Score = final_scores.mean() * 90\n",
    "    submission['Total Score'] = Total_Score\n",
    "    print(f\"Total score for {submission.Name} is {Total_Score} out of 90\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query ID</th>\n",
       "      <th>Question</th>\n",
       "      <th>ground_truth_Context</th>\n",
       "      <th>ground_truth_Answer</th>\n",
       "      <th>ground_truth_Sections</th>\n",
       "      <th>ground_truth_Pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Why did the English begin to focus more on Sri...</td>\n",
       "      <td>The English began to pay more attention to Sri...</td>\n",
       "      <td>The English began to focus on Sri Lanka due to...</td>\n",
       "      <td>2.2 The British focusing their Attention on Sr...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>What administrative practices did the British ...</td>\n",
       "      <td>When the English East India Trade Company gain...</td>\n",
       "      <td>The British East India Trade Company governed ...</td>\n",
       "      <td>Governance of the Coastal Areas under the East...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>What was the significance of the establishment...</td>\n",
       "      <td>A landmark in Buddhist education field was the...</td>\n",
       "      <td>The Parama Dhamma Chethiya Pirivena, founded b...</td>\n",
       "      <td>3.2 Buddhist Renaissance</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>What were the major contributions of Arumuga N...</td>\n",
       "      <td>There was a religious and a cultural renaissan...</td>\n",
       "      <td>Arumuga Navalar was a key leader of the Hindu ...</td>\n",
       "      <td>3.3 Hindu Religious Renaissance</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>What were the main reasons that led the upcoun...</td>\n",
       "      <td>Although the people of the upcountry could esc...</td>\n",
       "      <td>The people of the upcountry rose against the B...</td>\n",
       "      <td>2.4. Protests against Foreign Domination</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Query ID                                           Question  \\\n",
       "0         6  Why did the English begin to focus more on Sri...   \n",
       "1         7  What administrative practices did the British ...   \n",
       "2         8  What was the significance of the establishment...   \n",
       "3         9  What were the major contributions of Arumuga N...   \n",
       "4        10  What were the main reasons that led the upcoun...   \n",
       "\n",
       "                                ground_truth_Context  \\\n",
       "0  The English began to pay more attention to Sri...   \n",
       "1  When the English East India Trade Company gain...   \n",
       "2  A landmark in Buddhist education field was the...   \n",
       "3  There was a religious and a cultural renaissan...   \n",
       "4  Although the people of the upcountry could esc...   \n",
       "\n",
       "                                 ground_truth_Answer  \\\n",
       "0  The English began to focus on Sri Lanka due to...   \n",
       "1  The British East India Trade Company governed ...   \n",
       "2  The Parama Dhamma Chethiya Pirivena, founded b...   \n",
       "3  Arumuga Navalar was a key leader of the Hindu ...   \n",
       "4  The people of the upcountry rose against the B...   \n",
       "\n",
       "                               ground_truth_Sections  ground_truth_Pages  \n",
       "0  2.2 The British focusing their Attention on Sr...                  20  \n",
       "1  Governance of the Coastal Areas under the East...                  24  \n",
       "2                           3.2 Buddhist Renaissance                  43  \n",
       "3                    3.3 Hindu Religious Renaissance                  48  \n",
       "4           2.4. Protests against Foreign Domination                  32  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution = pd.read_csv(\"Solution.csv\")\n",
    "solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.4.1, however, your version is 3.1.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Akindu Himan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Akindu Himan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Akindu Himan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Akindu Himan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 1\n"
     ]
    },
    {
     "ename": "ParticipantVisibleError",
     "evalue": "Embedding computation failed for a row: 1 validation error for SingleTurnSample\nretrieved_contexts\n  Input should be a valid list [type=list_type, input_value='The English began to pay...ding the Bay of Bengal.', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.10/v/list_type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 50\u001b[0m, in \u001b[0;36mscore\u001b[1;34m(solution, submission, row_id_column_name)\u001b[0m\n\u001b[0;32m     48\u001b[0m Answer \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 50\u001b[0m context_precision_scores\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcalculate_context_precision\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQuestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth_Context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mContext\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     51\u001b[0m context_entity_recall_scores\u001b[38;5;241m.\u001b[39mappend(evaluate_context_entity_recall(ground_truth_Context, Context))\n",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m, in \u001b[0;36mcalculate_context_precision\u001b[1;34m(Question, ground_truth_Context, Context)\u001b[0m\n\u001b[0;32m      2\u001b[0m context_precision \u001b[38;5;241m=\u001b[39m LLMContextPrecisionWithReference(llm\u001b[38;5;241m=\u001b[39mwrapped_llm)\n\u001b[1;32m----> 3\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[43mSingleTurnSample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mQuestion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mground_truth_Context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretrieved_contexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mContext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m score \u001b[38;5;241m=\u001b[39m context_precision\u001b[38;5;241m.\u001b[39msingle_turn_ascore(sample)\n",
      "File \u001b[1;32mc:\\Users\\Akindu Himan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for SingleTurnSample\nretrieved_contexts\n  Input should be a valid list [type=list_type, input_value='The English began to pay...ding the Bay of Bengal.', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.10/v/list_type",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mParticipantVisibleError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m submission_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(submissions_folder, filename)\n\u001b[0;32m      5\u001b[0m submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(submission_path)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubmission\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQuery ID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[28], line 79\u001b[0m, in \u001b[0;36mscore\u001b[1;34m(solution, submission, row_id_column_name)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone 5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 79\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ParticipantVisibleError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedding computation failed for a row: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Convert to numpy arrays and clip values\u001b[39;00m\n\u001b[0;32m     82\u001b[0m context_matching_scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(np\u001b[38;5;241m.\u001b[39marray(context_matching_scores), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mParticipantVisibleError\u001b[0m: Embedding computation failed for a row: 1 validation error for SingleTurnSample\nretrieved_contexts\n  Input should be a valid list [type=list_type, input_value='The English began to pay...ding the Bay of Bengal.', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.10/v/list_type"
     ]
    }
   ],
   "source": [
    "submissions_folder = \"submissions\"\n",
    "for filename in os.listdir(submissions_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        submission_path = os.path.join(submissions_folder, filename)\n",
    "        submission = pd.read_csv(submission_path)\n",
    "        score(solution, submission, \"Query ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
